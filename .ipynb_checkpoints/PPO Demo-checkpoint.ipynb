{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ab4f39-d385-4c97-8356-767ed9161d2e",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "1. Put PPO files (actor, critic) in some models folder you will run thiws code in\n",
    "2. Copy the contents of the next cell into whatever file you want\n",
    "\n",
    "For reference, This is the rolling average (rolling from 5 timesteps) when model training was stopped:\n",
    "\n",
    "Rollouts:  86%|███████████████████████████████████████████████████▊        | 345/400 [02:41<00:25,  2.13it/s, loss=-145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e85f16-ae06-4157-b000-ce0f121374a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from state_indep_ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024fe27d-966c-4928-977f-a1304e6017b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pendulum Input Space = 3, pendulum output space = 1\n",
    "\n",
    "agent = PPO(3, 1)\n",
    "actor_path = \"models/PPO_Actor\"\n",
    "critic_path = \"models/PPO_Critic\"\n",
    "agent.actor.load_state_dict(torch.load(actor_path, weights_only=True))\n",
    "agent.critic.load_state_dict(torch.load(critic_path, weights_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec62b4-ee0f-41a5-8275-c146046c2ba7",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6672f8dc-0c21-4942-93bb-95da47fcf7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristongrayston/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "#env = gym.make(env_name, render_mode='human')\n",
    "import gym\n",
    "env = gym.make(\"Pendulum-v1\", render_mode='human')\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "observation, info = env.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    # Get the action from the trained PPO agent\n",
    "    vect_obs = torch.tensor(observation, dtype=torch.float32, device='cpu')\n",
    "    action, _ = agent.get_action(vect_obs)  # or .predict(...)\n",
    "    #print(action)\n",
    "    # Take a step in the environment\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "# Once the episode is done, close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770dec9-416f-4973-848c-bc9f21f890f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
