{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf448732-df0c-44e5-9209-59635ba8b985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 16:24:08.585503: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-16 16:24:09.164695: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-16 16:24:10.729179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ncps \n",
    "from ncps.torch import LTC\n",
    "from ncps.torch import CfC\n",
    "from ncps.wirings import AutoNCP\n",
    "import pytorch_lightning as pl\n",
    "import torch.utils.data as data\n",
    "import seaborn as sns\n",
    "from ncps.wirings import NCP\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6514174-1f7a-4581-8d08-d4083e73b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_point = np.array([10.61098536,  5.87720862, 34.48052002])\n",
    "params = [10, 28, 8/3]\n",
    "dt = 0.001\n",
    "\n",
    "num_samples = [100_000, 20_000, 5_000]\n",
    "\n",
    "def dpdt(point, params=params): #position\n",
    "\n",
    "    x,y,z = point\n",
    "    sig, rho, beta = params\n",
    "    \n",
    "    new_x = y*dt*sig + x*(1-dt*sig)\n",
    "    new_y = x*dt*(rho-z) + y*(1-dt)\n",
    "    new_z = x*y*dt + z*(1-dt*beta)\n",
    "    return np.array([new_x, new_y, new_z])\n",
    "\n",
    "def make_lorenz_rollout(num_samples):\n",
    "    positions = []\n",
    "    positions.append(initial_point)\n",
    "\n",
    "    # your dataset\n",
    "    for _ in range(num_samples):\n",
    "        positions.append(dpdt(positions[-1]))\n",
    "\n",
    "    positions = np.stack(positions)\n",
    "\n",
    "    labels = np.sum(np.sqrt(np.square(positions[1:num_samples+1] - positions[:num_samples])), axis=1)\n",
    "\n",
    "    return positions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058973d-c676-4989-a88e-d052e6db9e70",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659eac8a-bffb-4aad-a7b1-5b4ad3d0b55e",
   "metadata": {},
   "source": [
    "### NCPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c590904-a621-403e-b879-ce33f848ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = num_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693ec922-d0d2-4edd-b314-1def61dad323",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/CFC_state_dict_N100000/adj_mat.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m num_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(test_samples)\n\u001b[1;32m      9\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/CFC_state_dict_N\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_s\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/adj_mat.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     adj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/sens_mat.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/CFC_state_dict_N100000/adj_mat.npy'"
     ]
    }
   ],
   "source": [
    "out_features = 3\n",
    "in_features = 3\n",
    "\n",
    "#wiring = AutoNCP(6, out_features)  \n",
    "wiring = NCP(inter_neurons=6, command_neurons=5, motor_neurons=out_features,\n",
    "             sensory_fanout=4, inter_fanout=2, recurrent_command_synapses=4, motor_fanin=2)\n",
    "\n",
    "num_s = str(test_samples)\n",
    "PATH = f\"models/CFC_state_dict_N{num_s}\"\n",
    "\n",
    "with open(PATH + '/adj_mat.npy', 'rb') as f:\n",
    "    adj = np.load(f)\n",
    "\n",
    "with open(PATH + '/sens_mat.npy', 'rb') as f:\n",
    "    sens = np.load(f)\n",
    "\n",
    "wiring.adjacency_matrix = adj\n",
    "wiring.sensory_adjacency_matrix = sens\n",
    "\n",
    "ncps = CfC(in_features, wiring, batch_first=True, return_sequences=False) # change to cfc, what could go wrong?\n",
    "ncps.load_state_dict(torch.load(PATH+ \"/weights\", weights_only=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630afb0-5beb-420b-b835-01061146d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 3\n",
    "in_features = 3\n",
    "\n",
    "#wiring = AutoNCP(6, out_features)  \n",
    "wiring = NCP(inter_neurons=6, command_neurons=5, motor_neurons=out_features,\n",
    "             sensory_fanout=4, inter_fanout=2, recurrent_command_synapses=4, motor_fanin=2)\n",
    "\n",
    "ncps = CfC(in_features, wiring, batch_first=True, return_sequences=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc59521-dd95-4940-8beb-1445b3a3d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def parse_data(positions, traj_len, batch_size):\n",
    "    \"\"\"\n",
    "    positions: numpy array of shape (num_steps, input_dim)\n",
    "    traj_len : length of the trajectory for each (x,y) pair\n",
    "    batch_size: how many samples per mini-batch\n",
    "\n",
    "    Returns:\n",
    "       data_x of shape (num_batches, batch_size, input_dim)\n",
    "       data_y of shape (num_batches, batch_size, traj_len, input_dim)\n",
    "    \"\"\"\n",
    "    print(\"Positions shape:\", positions.shape)\n",
    "\n",
    "    # Normalize by p_max\n",
    "    p_max = np.max(positions)\n",
    "    p_min = np.min(positions)\n",
    "    positions = positions / p_max\n",
    "\n",
    "    # Collect (x, y) pairs\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(positions.shape[0] - traj_len):\n",
    "        x.append(positions[i, :])\n",
    "        y.append(positions[i + 1 : i + 1 + traj_len, :])\n",
    "\n",
    "    data_x = torch.FloatTensor(np.stack(x))  # (N, input_dim)\n",
    "    data_y = torch.FloatTensor(np.stack(y))  # (N, traj_len, input_dim)\n",
    "\n",
    "    # Truncate any leftover to make it divisible by batch_size\n",
    "    num_samples = data_x.shape[0]\n",
    "    remainder = num_samples % batch_size\n",
    "    if remainder != 0:\n",
    "        data_x = data_x[:-remainder]\n",
    "        data_y = data_y[:-remainder]\n",
    "\n",
    "    # Now reshape to (num_batches, batch_size, ...)\n",
    "    num_batches = data_x.shape[0] // batch_size\n",
    "    data_x = data_x.view(num_batches, batch_size, -1)\n",
    "    # data_y has shape (N, traj_len, input_dim)\n",
    "    data_y = data_y.view(num_batches, batch_size, data_y.shape[1], data_y.shape[2])\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "    \n",
    "def training_loop(model, positions, epochs, traj_len):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    losses = []\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    # Get data\n",
    "    x, y = parse_data(positions, traj_len = 1, batch_size=16)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i in range(x.shape[0]):\n",
    "\n",
    "            inputs = x[i]\n",
    "            labels = y[i]\n",
    "            print(inputs.shape, labels.shape)\n",
    "            noise = torch.randn(inputs.shape) * 0.005 # Add noise to states\n",
    "\n",
    "            inputs = inputs + noise\n",
    "\n",
    "            hx = None\n",
    "            outputs = []\n",
    "\n",
    "            for i in range(traj_len):\n",
    "                inputs, hx = model(inputs, hx)\n",
    "                inputs = inputs.unsqueeze(0)\n",
    "                print(inputs)\n",
    "                outputs.append(inputs)\n",
    "\n",
    "            outputs = torch.stack(outputs)\n",
    "            \n",
    "            model_loss = loss_fn(outputs, labels)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            model_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(model_loss.item())\n",
    "\n",
    "    return losses\n",
    "    \n",
    "\n",
    "traj_len = 2\n",
    "positions, _ = make_lorenz_rollout(test_samples)\n",
    "x, y = parse_data(positions, traj_len, 16)\n",
    "print(x.shape, \" \", y.shape)\n",
    "#print(x[0, :, :], \" \\n\", y[0, :, :])\n",
    "\n",
    "losses = training_loop(ncps, positions, 10, traj_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92d88f-7bc0-4452-9a4c-7422c223d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220ad3c-2eb9-48cf-9988-ef9077d5f6ac",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c7f37-e174-41c5-9948-7bf5b3e2faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Obtain the graph from the wiring.\n",
    "G = wiring.get_graph()\n",
    "\n",
    "# Separate nodes by type.\n",
    "sensory_nodes = [node for node, data in G.nodes(data=True) if data.get(\"neuron_type\") == \"sensory\"]\n",
    "inter_nodes   = [node for node, data in G.nodes(data=True) if data.get(\"neuron_type\") == \"inter\"]\n",
    "command_nodes = [node for node, data in G.nodes(data=True) if data.get(\"neuron_type\") == \"command\"]\n",
    "motor_nodes   = [node for node, data in G.nodes(data=True) if data.get(\"neuron_type\") == \"motor\"]\n",
    "\n",
    "# Assign fixed x-coordinates for a feed-forward layout:\n",
    "# x = 0 for sensory, 2 for inter, 4 for command, and 6 for motor.\n",
    "pos = {}\n",
    "layers = [\n",
    "    (\"sensory\", sensory_nodes),\n",
    "    (\"inter\", inter_nodes),\n",
    "    (\"command\", command_nodes),\n",
    "    (\"motor\", motor_nodes)\n",
    "]\n",
    "x_spacing = 2.0  # horizontal spacing between layers\n",
    "y_spacing = 1.0  # vertical spacing within a layer\n",
    "\n",
    "for layer_index, (layer_name, nodes) in enumerate(layers):\n",
    "    x = layer_index * x_spacing\n",
    "    n = len(nodes)\n",
    "    # Evenly space nodes vertically and center them if there's more than one.\n",
    "    for i, node in enumerate(sorted(nodes)):\n",
    "        y = (i - (n - 1) / 2) * y_spacing if n > 1 else 0\n",
    "        pos[node] = (x, y)\n",
    "\n",
    "# Separate edges into non-recurrent and recurrent (command -> command) edges.\n",
    "non_recurrent_edges = []\n",
    "recurrent_edges = []\n",
    "for u, v, d in G.edges(data=True):\n",
    "    # If both source and target are command neurons, mark as recurrent.\n",
    "    if G.nodes[u][\"neuron_type\"] == \"command\" and G.nodes[v][\"neuron_type\"] == \"command\":\n",
    "        recurrent_edges.append((u, v))\n",
    "    else:\n",
    "        non_recurrent_edges.append((u, v))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw nodes with different colors for each layer.\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=sensory_nodes, node_color='tab:olive', label='Sensory')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=inter_nodes,   node_color='tab:blue',   label='Inter')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=command_nodes, node_color='tab:orange', label='Command')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=motor_nodes,   node_color='tab:green',  label='Motor')\n",
    "\n",
    "# Draw non-recurrent edges with a gentle curve.\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos,\n",
    "    edgelist=non_recurrent_edges,\n",
    "    arrows=True,\n",
    "    arrowstyle='->',\n",
    "    connectionstyle='arc3, rad=0.2',  # gentle curve\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Draw recurrent edges with a more pronounced curve and a different color.\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos,\n",
    "    edgelist=recurrent_edges,\n",
    "    arrows=True,\n",
    "    arrowstyle='->',\n",
    "    connectionstyle='arc3, rad=0.4',  # increased curvature\n",
    "    edge_color='red',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Draw node labels.\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"Lorenz NCP\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c8f641-5008-49c5-b217-26c0dc213e0a",
   "metadata": {},
   "source": [
    "### Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab450abc-2cd7-47e2-9016-4343b855278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_world_model_residual():\n",
    "    xin_s = tf.keras.layers.Input((3,))\n",
    "\n",
    "    xs = tf.keras.layers.Dense(32, activation='swish')(xin_s)\n",
    "    xs = tf.keras.layers.Dense(32, activation='swish')(xs)\n",
    "    xs = tf.keras.layers.Dense(3)(xs)\n",
    "\n",
    "    xout = tf.keras.layers.Add()([xs,xin_s])\n",
    "    return tf.keras.models.Model(xin_s, xout)\n",
    "\n",
    "build_world_model_residual().summary()\n",
    "\n",
    "res = build_world_model_residual()\n",
    "res.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "PATH = f\"models/RESNET_state_dict_N{num_s}.weights.h5\"\n",
    "res.load_weights(PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f2fea-a328-44f2-b9c1-e72d06e5c0d0",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf598e-bbeb-40f2-aa16-49cf56adf599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, obs_space_size, action_space_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Sequential(\n",
    "            nn.Linear(obs_space_size + action_space_size, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.RNN(32, hidden_size, batch_first=True)\n",
    "\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, obs_space_size),\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "\n",
    "        out = self.l0(x)\n",
    "        out, ht = self.rnn(out, h0)\n",
    "        out = self.l1(out)\n",
    "        out = out[:, -1, :]\n",
    "        return out, ht\n",
    "\n",
    "obs_space_size = 3\n",
    "action_space_size = 0\n",
    "hidden_size = 16\n",
    "rnn = SimpleRNN(obs_space_size, action_space_size, hidden_size)\n",
    "\n",
    "num_s = str(test_samples)\n",
    "PATH = f\"models/RNN_state_dict_N{num_s}\"\n",
    "rnn.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733209e-ba78-435a-8ab4-a638b06d51de",
   "metadata": {},
   "source": [
    "# Liquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb174f3-8a01-451b-b9fa-9ef05572b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "liquid = LTC(in_features, out_features, batch_first=True, return_sequences=False)\n",
    "PATH = f\"models/LTC_N{num_s}\"\n",
    "liquid.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3feea-ec6b-46c5-a320-391c1241d374",
   "metadata": {},
   "source": [
    "# Cool Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd5a27-a1c6-4427-8c4a-b942e7f8a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = num_samples[2]\n",
    "positions, _ = make_lorenz_rollout(test_samples)\n",
    "\n",
    "print(positions.shape)\n",
    "\n",
    "p_max = np.max(positions)\n",
    "p_min = np.min(positions)\n",
    "\n",
    "# Add noise\n",
    "#positions = positions+np.random.randn(test_samples + 1,3) * 0.1\n",
    "\n",
    "# Scale\n",
    "positions = positions/p_max # (normalize to between 1 some negative number that won't be 1) \n",
    "\n",
    "x = []\n",
    "y = []\n",
    "traj_len = 5\n",
    "for i in range(test_samples - traj_len):\n",
    "    x.append(positions[i:i+traj_len])\n",
    "    y.append(positions[i+traj_len:i+traj_len+1])\n",
    "\n",
    "#print(x, y[0])\n",
    "#print(\" \")\n",
    "#print(x, y[1])\n",
    "data_x = np.stack(x)\n",
    "data_y = np.stack(y)\n",
    "\n",
    "t_inputs = torch.FloatTensor(data_x)\n",
    "print(t_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e807804-a659-4fd9-ac19-c5ac93d0d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to make them into batches of sequence lengths\n",
    "\n",
    "with torch.no_grad():\n",
    "    #rnn_pred = rnn.forward(t_inputs)[0].numpy()\n",
    "    ncps_pred = ncps(t_inputs)[0].numpy()\n",
    "\n",
    "#res_pred = np.array(res.predict(positions[0:-1]))\n",
    "#res_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074dc3b-b4bd-4f87-95da-21c3842f651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example data\n",
    "# t_inputs = torch.FloatTensor(inputs).unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     liq_pred = liquid(t_inputs)[0].numpy()\n",
    "#     rnn_pred = rnn.forward(t_inputs)[0].numpy()\n",
    "# res_pred = np.array(res.predict(inputs))\n",
    "\n",
    "# For demonstration, assume these are each [T, 3] arrays:\n",
    "# liq_pred, rnn_pred, res_pred, inputs\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the real data (inputs) as a thick line with no transparency\n",
    "ax.plot(positions[:, 0], positions[:, 1], positions[:, 2], linewidth=5, alpha=1.0, label='Real', color='black')\n",
    "\n",
    "# Plot predicted trajectories with thinner lines and partial transparency\n",
    "ax.plot(ncps_pred[:, 0], ncps_pred[:, 1], ncps_pred[:, 2],\n",
    "         linewidth=2, alpha=1, label='NCPS Prediction')\n",
    "ax.plot(rnn_pred[:, 0], rnn_pred[:, 1], rnn_pred[:, 2],\n",
    "        linewidth=2, alpha=1, label='RNN Prediction')\n",
    "ax.plot(res_pred[:, 0], res_pred[:, 1], res_pred[:, 2],\n",
    "         linewidth=2, alpha=1, label='Res Prediction')\n",
    "\n",
    "# Create small shaded polygons connecting each real point to the corresponding\n",
    "# predicted points. This can be visually heavy if T is large, so consider\n",
    "# downsampling if needed.\n",
    "\n",
    "\n",
    "# Label the axes and set a title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('3D Trajectories Comparison')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d38cb0-4b66-47a0-800b-e951af145b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = num_samples[2]\n",
    "initial_point = np.array([-0.510, -0.4218712, -0.23523])\n",
    "dt = 0.003\n",
    "positions, _ = make_lorenz_rollout(test_samples)\n",
    "\n",
    "print(positions.shape)\n",
    "\n",
    "p_max = np.max(positions)\n",
    "p_min = np.min(positions)\n",
    "\n",
    "# Add noise\n",
    "positions = positions+np.random.randn(test_samples + 1,3) * 0.1\n",
    "\n",
    "# Scale\n",
    "positions = positions/p_max # (normalize to between 1 some negative number that won't be 1) \n",
    "\n",
    "x = []\n",
    "y = []\n",
    "traj_len = 5\n",
    "for i in range(test_samples - traj_len):\n",
    "    x.append(positions[i:i+traj_len])\n",
    "    y.append(positions[i+traj_len:i+traj_len+1])\n",
    "\n",
    "#print(x, y[0])\n",
    "#print(\" \")\n",
    "#print(x, y[1])\n",
    "data_x = np.stack(x)\n",
    "data_y = np.stack(y)\n",
    "\n",
    "inputs = positions[0:-1]\n",
    "t_inputs = torch.FloatTensor(data_x)\n",
    "print(t_inputs.shape)\n",
    "print(inputs.shape)\n",
    "\n",
    "# now we have to make them into batches of sequence lengths\n",
    "\n",
    "with torch.no_grad():\n",
    "    liq_pred = liquid(t_inputs)[0].numpy()\n",
    "    ncps_pred = liquid(t_inputs)[0].numpy()\n",
    "    rnn_pred = rnn.forward(t_inputs)[0].numpy()\n",
    "\n",
    "res_pred = np.array(res.predict(inputs))\n",
    "res_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c64054-ba78-40a0-84f6-a2225f45fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example data\n",
    "# t_inputs = torch.FloatTensor(inputs).unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     liq_pred = liquid(t_inputs)[0].numpy()\n",
    "#     rnn_pred = rnn.forward(t_inputs)[0].numpy()\n",
    "# res_pred = np.array(res.predict(inputs))\n",
    "\n",
    "# For demonstration, assume these are each [T, 3] arrays:\n",
    "# liq_pred, rnn_pred, res_pred, inputs\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the real data (inputs) as a thick line with no transparency\n",
    "ax.plot(inputs[:, 0], inputs[:, 1], inputs[:, 2],\n",
    "     linewidth=5, alpha=1.0, label='Real', color='black')\n",
    "\n",
    "# Plot predicted trajectories with thinner lines and partial transparency\n",
    "ax.plot(ncps_pred[:, 0], ncps_pred[:, 1], ncps_pred[:, 2],\n",
    "         linewidth=2, alpha=1, label='NCPS Prediction')\n",
    "#ax.plot(liq_pred[:, 0], liq_pred[:, 1], liq_pred[:, 2],\n",
    "#        linewidth=2, alpha=1, label='Liquid Prediction')\n",
    "ax.plot(rnn_pred[:, 0], rnn_pred[:, 1], rnn_pred[:, 2],\n",
    "   linewidth=2, alpha=1, label='RNN Prediction')\n",
    "ax.plot(res_pred[:, 0], res_pred[:, 1], res_pred[:, 2],\n",
    "      linewidth=2, alpha=1, label='Res Prediction')\n",
    "\n",
    "# Create small shaded polygons connecting each real point to the corresponding\n",
    "# predicted points. This can be visually heavy if T is large, so consider\n",
    "# downsampling if needed.\n",
    "\n",
    "# Label the axes and set a title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('OOD 3D Trajectories - One Step Comparison')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e09b8-b10e-4811-9c83-8659eb5ec9f5",
   "metadata": {},
   "source": [
    "# Multi-Step Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ddd0c-d2d5-4e48-b15b-6f98cafbb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rolling_inputs = r_rolling_inputs = n_rolling_inputs = t_inputs[0]\n",
    "print(t_inputs[0])\n",
    "window = inputs.shape[1]\n",
    "\n",
    "r_rolling_inputs = r_rolling_inputs.unsqueeze(axis=0)\n",
    "\n",
    "#print(r_rolling_inputs.shape)\n",
    "\n",
    "liquid_predictions = []\n",
    "rnn_predictions = []\n",
    "ncps_predictions = []\n",
    "\n",
    "num_predictions = 10_000\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    with torch.no_grad():\n",
    "        l_prediction = liquid(l_rolling_inputs)[0].unsqueeze(0)\n",
    "        r_prediction = rnn(r_rolling_inputs)[0].unsqueeze(0)\n",
    "        n_prediction = ncps(n_rolling_inputs)[0].unsqueeze(0)\n",
    "\n",
    "\n",
    "    liquid_predictions.append(l_prediction)\n",
    "    rnn_predictions.append(r_prediction)\n",
    "    ncps_predictions.append(n_prediction)\n",
    "    \n",
    "    #prediction = torch.FloatTensor(np.expand_dims(prediction, axis=0))\n",
    "    #print(r_prediction.shape)\n",
    "    #print(r_rolling_inputs.shape)\n",
    "    \n",
    "    l_rolling_inputs = torch.concatenate((l_rolling_inputs[1:window+1], l_prediction))\n",
    "    r_rolling_inputs = torch.concatenate((r_rolling_inputs[:, 1:window+1, :], r_prediction), axis=1)\n",
    "    n_rolling_inputs = torch.concatenate((n_rolling_inputs[1:window+1], n_prediction))\n",
    "\n",
    "\n",
    "    print(n_rolling_inputs, \" \", prediction)\n",
    "\n",
    "\n",
    "#predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578217d0-7407-430d-8239-dab4f13c698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liquid_predictions = torch.stack(liquid_predictions).squeeze(1).numpy()\n",
    "rnn_predictions = torch.stack(rnn_predictions).squeeze(1).numpy()\n",
    "ncps_predictions = torch.stack(ncps_predictions).squeeze(1).numpy()\n",
    "liquid_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497d4d1d-cfff-41a9-bee7-7c06d97278ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mliquid_predictions\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      2\u001b[0m rnn_predictions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m ncps_predictions\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_predictions.shape\n",
    "rnn_predictions.shape\n",
    "ncps_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21576ec9-2195-48b6-b1cd-c0dca27a6e72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mliquid_predictions\u001b[49m[\u001b[38;5;241m2\u001b[39m, :]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_predictions[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bda353b1-9451-4fa2-8e7c-93883bd3418b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m, :]\n\u001b[1;32m      2\u001b[0m start\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "start = inputs[3:4, :]\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd19528-1da8-4c0b-826b-b23ac661612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_prediction = []\n",
    "#start = res(t_inputs[0, -1, :].unsqueeze(0).numpy())\n",
    "print(start)\n",
    "res_prediction.append(np.array(res(start)))\n",
    "for i in range(num_predictions-1):\n",
    "    # random action\n",
    "    _state = np.array(res(res_prediction[-1]))\n",
    "    #print(_state.shape)\n",
    "    # pend length\n",
    "    res_prediction.append(_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24fb6138-adcd-472b-9c8e-cc9f12a02a53",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_prediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res_prediction\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:460\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    458\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    462\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "res_prediction = np.stack(res_prediction)\n",
    "res_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b17e90-858a-4892-a300-280e66ff6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the real data (inputs) as a thick line with no transparency\n",
    "ax.plot(positions[:, 0], positions[:, 1], positions[:, 2],\n",
    "     linewidth=1, alpha=0.2, label='Real', color='black')\n",
    "\n",
    "#Plot predicted trajectories with thinner lines and partial transparency\n",
    "ax.plot(ncps_predictions[:, 0], ncps_predictions[:, 1], ncps_predictions[:, 2],\n",
    "        linewidth=2, alpha=1, label='NCPS Prediction')\n",
    "ax.plot(liquid_predictions[:, 0], liquid_predictions[:, 1], liquid_predictions[:, 2],\n",
    "        linewidth=2, alpha=1, label='Liquid Prediction')\n",
    "ax.plot(rnn_predictions[:,0, 0], rnn_predictions[:, 0, 1], rnn_predictions[:,0, 2],\n",
    "   linewidth=2, alpha=1, label='RNN Prediction')\n",
    "ax.plot(res_prediction[:, 0, 0], res_prediction[:, 0, 1], res_prediction[:, 0, 2],\n",
    "      linewidth=2, alpha=1, label='Res Prediction')\n",
    "\n",
    "# Create small shaded polygons connecting each real point to the corresponding\n",
    "# predicted points. This can be visually heavy if T is large, so consider\n",
    "# downsampling if needed.\n",
    "\n",
    "# Label the axes and set a title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('100k Step Prediction')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cac2f9-7df2-4183-a9c7-50931423706d",
   "metadata": {},
   "source": [
    "# Decoherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e0f386a-b939-4689-abd8-09d18fe3f252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5351068617084742"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set an arbitrary X, an upper bound for max euclidean distance \n",
    "initial_point = np.array([10.61098536,  5.87720862, 34.48052002])\n",
    "params = [10, 28, 8/3]\n",
    "dt = 0.001\n",
    "\n",
    "positions, labels = make_lorenz_rollout(test_samples)\n",
    "positions /= np.max(positions)\n",
    "labels /= np.max(positions)\n",
    "X = np.max(labels) + 1/4 * np.max(labels)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a0dea6-995a-493b-80ef-57d868c0f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "start_positions = np.random.randint(5, test_samples - 100, size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39fcecc1-3e8d-443f-842e-0451fa7f3a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 5, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for residuals\n",
    "test_positions_rec = []\n",
    "real_positions = []\n",
    "for i in range(5):\n",
    "    test_positions_rec.append(positions[start_positions-5+i, :])\n",
    "\n",
    "for i in range(100):\n",
    "    real_positions.append(positions[start_positions+i, :])\n",
    "    \n",
    "test_positions_rec = np.stack(test_positions_rec)\n",
    "real_positions = np.stack(real_positions).swapaxes(0, 1)\n",
    "print(real_positions.shape)\n",
    "\n",
    "test_positions_residual = test_positions_rec[-1, :, :]\n",
    "test_positions_rec = test_positions_rec.swapaxes(0, 1)\n",
    "test_positions_rec.shape\n",
    "\n",
    "#print(test_positions_rec[0, :, :], real_positions[0, 0, :])\n",
    "#print(positions[start_positions[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6815c873-6cdb-4ac2-a706-14290108fdb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l_rolling_inputs \u001b[38;5;241m=\u001b[39m r_rolling_inputs \u001b[38;5;241m=\u001b[39m n_rolling_inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(test_positions_rec)\n\u001b[0;32m----> 2\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(r_rolling_inputs.shape)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m liquid_predictions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "l_rolling_inputs = r_rolling_inputs = n_rolling_inputs = torch.FloatTensor(test_positions_rec)\n",
    "window = inputs.shape[1]\n",
    "\n",
    "#print(r_rolling_inputs.shape)\n",
    "\n",
    "liquid_predictions = []\n",
    "rnn_predictions = []\n",
    "ncps_predictions = []\n",
    "\n",
    "num_predictions = 100\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    with torch.no_grad():\n",
    "        l_prediction = liquid(l_rolling_inputs)[0].unsqueeze(0).swapaxes(0, 1)\n",
    "        r_prediction = rnn(r_rolling_inputs)[0].unsqueeze(0).swapaxes(0, 1)\n",
    "        n_prediction = ncps(n_rolling_inputs)[0].unsqueeze(0).swapaxes(0, 1)\n",
    "\n",
    "\n",
    "    #print(l_prediction.shape, \" \", r_prediction.shape)\n",
    "    liquid_predictions.append(l_prediction)\n",
    "    rnn_predictions.append(r_prediction)\n",
    "    ncps_predictions.append(n_prediction)\n",
    "    #print(l_rolling_inputs.shape, \" \", r_rolling_inputs.shape)\n",
    "    \n",
    "    #prediction = torch.FloatTensor(np.expand_dims(prediction, axis=0))\n",
    "    #print(r_prediction.shape)\n",
    "    #print(r_rolling_inputs.shape)\n",
    "\n",
    "    l_rolling_inputs = torch.concatenate((l_rolling_inputs[:, 1:window+2, :], l_prediction), axis=1)\n",
    "    r_rolling_inputs = torch.concatenate((r_rolling_inputs[:, 1:window+2, :], r_prediction), axis=1)\n",
    "    n_rolling_inputs = torch.concatenate((n_rolling_inputs[:, 1:window+2, :], n_prediction), axis=1)\n",
    "\n",
    "\n",
    "    #print(rolling_inputs, \" \", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7515a1d8-7bca-4515-9c75-974d1f7ca84d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m liquid_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43mliquid_predictions\u001b[49m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m rnn_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(rnn_predictions)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m ncps_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(ncps_predictions)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_predictions = torch.stack(liquid_predictions).squeeze(2).numpy().swapaxes(0, 1)\n",
    "rnn_predictions = torch.stack(rnn_predictions).squeeze(2).numpy().swapaxes(0, 1)\n",
    "ncps_predictions = torch.stack(ncps_predictions).squeeze(2).numpy().swapaxes(0, 1)\n",
    "liquid_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3ab1b0-8dbb-46d9-9329-4cd1501ec870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m liquid_res \u001b[38;5;241m=\u001b[39m \u001b[43mliquid_predictions\u001b[49m \u001b[38;5;241m-\u001b[39m real_positions\n\u001b[1;32m      2\u001b[0m liquid_predictions\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(liquid_predictions[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :], real_positions[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :] , liquid_res[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_res = liquid_predictions - real_positions\n",
    "liquid_predictions\n",
    "print(liquid_predictions[0, 0, :], real_positions[0, 0, :] , liquid_res[0, 0, :])\n",
    "liquid_res_summed = np.sum(np.abs(liquid_res[0]), axis=-1)\n",
    "liquid_res_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe7feca-1396-4322-a6c0-8f4596e0cb1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m liquid_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msquare(\u001b[43mliquid_predictions\u001b[49m \u001b[38;5;241m-\u001b[39m real_positions)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m rnn_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msquare(rnn_predictions \u001b[38;5;241m-\u001b[39m real_positions)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m ncps_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msquare(ncps_predictions \u001b[38;5;241m-\u001b[39m real_positions)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_res = np.sum(np.sqrt(np.square(liquid_predictions - real_positions)), axis=-1)\n",
    "rnn_res = np.sum(np.sqrt(np.square(rnn_predictions - real_positions)), axis=-1)\n",
    "ncps_res = np.sum(np.sqrt(np.square(ncps_predictions - real_positions)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f93c64-f5fe-4192-b671-6df6dce47598",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mliquid_res\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_res' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b579188-7e5f-4272-923b-66d70ee93dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mliquid_res\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_res' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f51c4d4c-ea31-43f6-b498-882215bee835",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquid_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m liquid_mask \u001b[38;5;241m=\u001b[39m (\u001b[43mliquid_res\u001b[49m \u001b[38;5;241m>\u001b[39m X)\n\u001b[1;32m      2\u001b[0m res_mask \u001b[38;5;241m=\u001b[39m (ncps_res \u001b[38;5;241m>\u001b[39m X)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liquid_res' is not defined"
     ]
    }
   ],
   "source": [
    "liquid_mask = (liquid_res > X)\n",
    "res_mask = (ncps_res > X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc14ac4-21a2-474a-954e-18819cb03e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1b990-00d6-4331-a9c1-4270efe950c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1151927-69a1-474f-a1ff-e5b7d6ba7c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8031c-0b9b-4bd0-9608-f69af50bbcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf1902-9fe3-4aa0-a671-5f15a67df597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad934d-d364-4e14-a809-521042bc5796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750289d-bbc7-4c41-95e0-6266255d0a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c7747-160b-4bc6-8136-28d38c3df70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0a2a2-77ac-41a6-9f28-da764555df73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3923456-d1a3-4373-940f-ddc1ee46f51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02686d3-cade-4bd3-8de7-8ed5cd03bc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecd0bd-ced5-4000-bda6-ffae1b6c7ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f13fa3-5b56-42ad-8719-de4afe1e968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfc62f-7f21-48e6-be0e-9d12d3120ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19971fca-c702-4731-a021-43c4ed1d0c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae51d59-05fc-4b2b-97d6-7b5a479f81bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1f928-d2a8-4423-b31a-770baafbbf55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
